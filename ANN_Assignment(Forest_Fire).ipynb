{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Forest Fires**"
      ],
      "metadata": {
        "id": "strY98Z_rweT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3EEmz_k-fdM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/forestfires.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "gXJfwHJf_-20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploratory Data Analysis**"
      ],
      "metadata": {
        "id": "VsYin4PBBn0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "TdItxheuBuQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "dXi8TCaoAQz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.size"
      ],
      "metadata": {
        "id": "G5QLrmDcAneB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "oCtCVHxQApem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "bhCglJfJAsJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "quCBIMWMAwZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "0mu4Sh6yBfH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop for getting Categorical data\n",
        "for column in df.columns:\n",
        "  if df[column].dtype == 'object':\n",
        "    print(column)"
      ],
      "metadata": {
        "id": "S81m03GcAx8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop for getting Continuous data\n",
        "for column in df.columns:\n",
        "  if df[column].dtype != 'object':\n",
        "    print(column)"
      ],
      "metadata": {
        "id": "RcZpBelNBJ2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Correlation Matrix**"
      ],
      "metadata": {
        "id": "vGiqnZYgB1ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.corr()"
      ],
      "metadata": {
        "id": "z6LuHVDQBaT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(30,15))\n",
        "sns.heatmap(df.corr(),annot = True,cmap = 'RdYlGn')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lzpVzWH0B5Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Continuous = ['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind',\n",
        "       'rain', 'area', 'dayfri', 'daymon', 'daysat', 'daysun', 'daythu',\n",
        "       'daytue', 'daywed', 'monthapr', 'monthaug', 'monthdec', 'monthfeb',\n",
        "       'monthjan', 'monthjul', 'monthjun', 'monthmar', 'monthmay', 'monthnov',\n",
        "       'monthoct', 'monthsep' ]\n",
        "Category =['month','day','size_category']"
      ],
      "metadata": {
        "id": "Duvr83FkC2f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Distribution of Continuous**"
      ],
      "metadata": {
        "id": "-dq1SSE1CwBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for feature in Continuous:\n",
        "  sns.displot(data = df, x = feature, height = 7,aspect = 2, color = '#158685')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "eaZAzCDtCCcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Distribution of Category**"
      ],
      "metadata": {
        "id": "xy1rdi5tDSRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for feature in Category:\n",
        "  sns.countplot(data = df, x = feature , palette='deep')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "6TQafg8eDJmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Box Plot**"
      ],
      "metadata": {
        "id": "EvZa8U6gDwOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind',\n",
        "       'rain', 'area', 'dayfri', 'daymon', 'daysat', 'daysun', 'daythu',\n",
        "       'daytue', 'daywed', 'monthapr', 'monthaug', 'monthdec', 'monthfeb',\n",
        "       'monthjan', 'monthjul', 'monthjun', 'monthmar', 'monthmay', 'monthnov',\n",
        "       'monthoct', 'monthsep']\n",
        "for col in columns:\n",
        "    plt.figure()   # plots figure for each iteration\n",
        "    sns.boxplot(df[col])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3Q80mtu5DrID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dist Plot**"
      ],
      "metadata": {
        "id": "mSNS1hvdD3nw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for cols in columns:\n",
        "  plt.figure()\n",
        "  sns.distplot(df[col])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "U8bynFFSD1El"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Violin Plot**"
      ],
      "metadata": {
        "id": "JkAyfRSHELTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in columns:\n",
        "  plt.figure()\n",
        "  sns.violinplot(df[col])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "a-eLiQ3oEAfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Encoding the Categorical Variable**"
      ],
      "metadata": {
        "id": "bta7GKeXEZhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(labels = ['month','day'], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "zOXu1CiPERIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "qOiNYJ2UEpLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df['size_category'] = le.fit_transform(df['size_category'])"
      ],
      "metadata": {
        "id": "qPO6HpM8Eshs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Dl1smh3fE88W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['size_category'].value_counts()"
      ],
      "metadata": {
        "id": "pCwl4wIgE_Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see tha in size_category the small observations are 378 and the large observations are 139.\n",
        "\n",
        "Here the data is imbalanced."
      ],
      "metadata": {
        "id": "3K_oU9GJW97Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Defining Independent and Dependent Variable**"
      ],
      "metadata": {
        "id": "MkAkubpNGLpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('size_category',axis = 1)\n",
        "Y = df.iloc[:,-1]"
      ],
      "metadata": {
        "id": "IDnbE-0RGIue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "ErKdUEhSGRYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y.head()"
      ],
      "metadata": {
        "id": "3DCNVuPiGTBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape,Y.shape"
      ],
      "metadata": {
        "id": "8Qk7hbvnGUke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Balancing the data by Smote**"
      ],
      "metadata": {
        "id": "WmHNkygGXLMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y.value_counts()"
      ],
      "metadata": {
        "id": "ug4Fy8KpXKIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(sampling_strategy = 'minority')\n",
        "\n",
        "oversample = SMOTE()\n",
        "X, Y = oversample.fit_resample(X, Y)\n",
        "\n",
        "Y.value_counts()"
      ],
      "metadata": {
        "id": "1S6JWmMxYOEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, here the data is balanced so we can now move further."
      ],
      "metadata": {
        "id": "JzwtcKvbYmiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Scaling the Data**"
      ],
      "metadata": {
        "id": "iyEbs0KgFpzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardization\n",
        "a = StandardScaler()\n",
        "a.fit(X)\n",
        "X_standardized = a.transform(X)"
      ],
      "metadata": {
        "id": "Omo3qqKqLdCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_standardized.shape"
      ],
      "metadata": {
        "id": "GFdZxIlnNPmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(X_standardized)"
      ],
      "metadata": {
        "id": "7H73VM0hF-20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Splitting the data into Training and Testing dataset**"
      ],
      "metadata": {
        "id": "Vj3lV1-XYspq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3,random_state=42)"
      ],
      "metadata": {
        "id": "tC1WCNuvSdyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape,X_test.shape"
      ],
      "metadata": {
        "id": "K88puRvtYwAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tuning the Hyperparameters :- Batch size and Epochs**"
      ],
      "metadata": {
        "id": "jaKYE-UHKdrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import adam_v2"
      ],
      "metadata": {
        "id": "wZ38whn0KlSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "def create_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(30, input_dim = 28, kernel_initializer='uniform',activation='relu')) \n",
        "  model.add(Dense(25, kernel_initializer='uniform',activation='relu'))\n",
        "  model.add(Dense(1, kernel_initializer='uniform',activation='sigmoid'))\n",
        "\n",
        "  adam = adam_v2.Adam(lr = 0.01)\n",
        "\n",
        "  model.compile(loss = 'binary_crossentropy',\n",
        "                optimizer = adam,\n",
        "                metrics = ['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "FM_9iDiSKoTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = KerasClassifier(build_fn = create_model, verbose = 0)\n",
        "\n",
        "\n",
        "# Define the grid search parameter\n",
        "batch_size = [10,20,40,60]\n",
        "epochs = [10,50,100,150]\n",
        "\n",
        "#Make a dictionary of the grid search parameters\n",
        "param_grid = dict(batch_size = batch_size,\n",
        "                  epochs = epochs)\n",
        "\n",
        "# Build and fit the GridSearchCV\n",
        "grid = GridSearchCV(estimator = model,\n",
        "                    param_grid = param_grid,\n",
        "                    cv = KFold(),\n",
        "                    verbose = 10)\n",
        "\n",
        "grid_result = grid.fit(X_standardized, Y)"
      ],
      "metadata": {
        "id": "rjdMVuD7K8xS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize the results\n",
        "print('Best : {}, using {}' .format(grid_result.best_score_,grid_result.best_params_))\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "for mean,stdev,param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean,stdev, param))"
      ],
      "metadata": {
        "id": "W-r2XK46MOXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tuning of Hyperparameters:-Learning Rate and Drop out rate**"
      ],
      "metadata": {
        "id": "DiQuSuQXXMG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dropout\n",
        "\n",
        "# Defining the model\n",
        "def create_model(learning_rate, dropout_rate):\n",
        "  model1 = Sequential()\n",
        "  model1.add(Dense(30, input_dim = 28, kernel_initializer='uniform',activation='relu'))\n",
        "  model1.add(Dropout(dropout_rate))\n",
        "  model1.add(Dense(25, input_dim = 28, kernel_initializer='uniform',activation='relu'))\n",
        "  model1.add(Dropout(dropout_rate))\n",
        "  model1.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "  adam = adam_v2.Adam(lr = learning_rate)\n",
        "\n",
        "  model1.compile(loss = 'binary_crossentropy',\n",
        "                optimizer = adam,\n",
        "                metrics = ['accuracy'])\n",
        "  return model1"
      ],
      "metadata": {
        "id": "a6yFoSMfVNTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model1 = KerasClassifier(build_fn = create_model, \n",
        "                        verbose = 0,\n",
        "                        batch_size = 20,\n",
        "                        epochs = 150)\n",
        "\n",
        "\n",
        "# Define the grid search parameter\n",
        "learning_rate = [0.001,0.01,0.1]\n",
        "dropout_rate= [0.0,0.1,0.2]\n",
        "\n",
        "#Make a dictionary of the grid search parameters\n",
        "param_grid = dict(learning_rate = learning_rate,\n",
        "                  dropout_rate = dropout_rate)\n",
        "\n",
        "# Build and fit the GridSearchCV\n",
        "grid = GridSearchCV(estimator = model1,\n",
        "                    param_grid = param_grid,\n",
        "                    cv = KFold(),\n",
        "                    verbose = 10)\n",
        "\n",
        "grid_result = grid.fit(X_standardized, Y)"
      ],
      "metadata": {
        "id": "k637SREeXVkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize the results\n",
        "print('Best : {}, using {}' .format(grid_result.best_score_,grid_result.best_params_))\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "for mean,stdev,param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean,stdev, param))"
      ],
      "metadata": {
        "id": "oKdhc-X1XZTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tuning of Hyperparameters:- Activation Function and Kernel Initializer**"
      ],
      "metadata": {
        "id": "pjgvLUISZ6do"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the model\n",
        "\n",
        "def create_model(activation_function,init):\n",
        "    model2 = Sequential()\n",
        "    model2.add(Dense(30,input_dim = 28,kernel_initializer = init,activation = activation_function))\n",
        "    model2.add(Dropout(0.2))\n",
        "    model2.add(Dense(25,input_dim = 28,kernel_initializer = init,activation = activation_function))\n",
        "    model2.add(Dropout(0.2))\n",
        "    model2.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    adam = adam_v2.Adam(lr = 0.001)\n",
        "    model2.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
        "    return model2\n",
        "\n",
        "# Create the model\n",
        "\n",
        "model2 = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 20,epochs = 150)\n",
        "\n",
        "# Define the grid search parameters\n",
        "activation_function = ['softmax','relu','tanh','linear']\n",
        "init = ['uniform','normal','zero']\n",
        "\n",
        "# Make a dictionary of the grid search parameters\n",
        "param_grids = dict(activation_function = activation_function,init = init)\n",
        "\n",
        "# Build and fit the GridSearchCV\n",
        "\n",
        "grid = GridSearchCV(estimator = model2,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
        "grid_result = grid.fit(X_standardized,Y)"
      ],
      "metadata": {
        "id": "J6KrqJDpZ1wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize the results\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "metadata": {
        "id": "IrN2sN0NaEfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Tuning of Hyperparameter :-Number of Neurons in activation layer**"
      ],
      "metadata": {
        "id": "-Z2d-BGHbE6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the model\n",
        "\n",
        "def create_model(neuron1,neuron2):\n",
        "    model3 = Sequential()\n",
        "    model3.add(Dense(neuron1,input_dim = 28,kernel_initializer = 'normal',activation = 'tanh'))\n",
        "    model3.add(Dropout(0.2))\n",
        "    model3.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'normal',activation = 'tanh'))\n",
        "    model3.add(Dropout(0.2))\n",
        "    model3.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    adam = adam_v2.Adam(lr = 0.001)\n",
        "    model3.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
        "    return model3\n",
        "\n",
        "# Create the model\n",
        "\n",
        "model3 = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 20,epochs = 150)\n",
        "\n",
        "# Define the grid search parameters\n",
        "\n",
        "neuron1 = [4,8,16,18,25,30,35]\n",
        "neuron2 = [2,4,8,16,18,25,30]\n",
        "\n",
        "# Make a dictionary of the grid search parameters\n",
        "\n",
        "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
        "\n",
        "# Build and fit the GridSearchCV\n",
        "\n",
        "grid = GridSearchCV(estimator = model3,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
        "grid_result = grid.fit(X_standardized,Y)"
      ],
      "metadata": {
        "id": "_7FkVLUOaqGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize the results\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "metadata": {
        "id": "tRZpzbQbbelI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training model with optimum values of Hyperparameters**"
      ],
      "metadata": {
        "id": "58YqqP54yJf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Defining the model\n",
        "\n",
        "def create_model():\n",
        "    model4 = Sequential()\n",
        "    model4.add(Dense(8,input_dim = 28,kernel_initializer = 'normal',activation = 'tanh'))\n",
        "    model4.add(Dropout(0.2))\n",
        "    model4.add(Dense(18,input_dim = 8,kernel_initializer = 'normal',activation = 'tanh'))\n",
        "    model4.add(Dropout(0.2))\n",
        "    model4.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    adam = adam_v2.Adam(lr = 0.001) #sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
        "    model4.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
        "    return model4\n",
        "\n",
        "# Create the model\n",
        "\n",
        "model4 = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 20,epochs = 150)\n",
        "\n",
        "# Fitting the model\n",
        "\n",
        "model4.fit(X_standardized,Y)\n",
        "\n",
        "# Predicting using trained model\n",
        "\n",
        "Y_predict = model4.predict(X_standardized)\n",
        "\n",
        "# Printing the metrics\n",
        "print(accuracy_score(Y,Y_predict))"
      ],
      "metadata": {
        "id": "jQe7wmmJfP3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building Neural Networks Model using Optimal Values**"
      ],
      "metadata": {
        "id": "yNYdT5Tfrhb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # create ANN model\n",
        "model = Sequential()\n",
        "# Defining the first layer of the model\n",
        "model.add(Dense(units=8, input_dim=X_train.shape[1], kernel_initializer='normal', activation='tanh'))\n",
        "model.add(Dropout(0.2))        \n",
        "# Defining the Second layer of the model\n",
        "model.add(Dense(units=18, kernel_initializer='normal', activation='tanh'))\n",
        "model.add(Dropout(0.2))  \n",
        "# The output neuron is a single fully connected node \n",
        "# Since we will be predicting a single number\n",
        "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='Adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the model with best parameters\n",
        "history = model.fit(X_train, Y_train, validation_split=0.33, batch_size = 20, epochs = 150)"
      ],
      "metadata": {
        "id": "DLUImH2rT9SU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "scores = model.evaluate(X,Y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "id": "KlMUSIifPDJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.metrics_names"
      ],
      "metadata": {
        "id": "oBwkRPxTP5-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "id": "CwRNhqERP6CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize training history\n",
        "\n",
        "#list all data in history\n",
        "history.history.keys()"
      ],
      "metadata": {
        "id": "u2Q3f69irCJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Summarize history for accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w-pwY3SIPWea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Summarize history for loss\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LVxoGn8vrEUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SHJec-6yrGtF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}